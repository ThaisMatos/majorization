{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bitvenvvirtualenv76aacd352c7a46bc9e8335aecdb5fbc9",
   "display_name": "Python 3.7.6 64-bit ('venv': virtualenv)",
   "language": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_less_than(v1,v2):\n",
    "    return np.sum(v1) < np.sum(v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_equal(v1,v2):\n",
    "    return np.isclose(np.sum(v1),np.sum(v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_rule(v1,v2):\n",
    "    return is_less_than(v1,v2) or is_equal(v1,v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_a_valid_pair(v1,v2):\n",
    "    for idx in range(1,len(v1)): #ignoring last sum because all vectors sum 1\n",
    "        if not check_rule(v1[:idx], v2[:idx]):\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_string_to_list(column):\n",
    "    # return column.apply(lambda cell: np.fromstring(cell[1:-1], dtype=np.float64, sep=' '))\n",
    "    return column.apply(lambda cell: np.array(literal_eval(cell)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, train_percent=.8):\n",
    "    n_samples = df.shape[0]\n",
    "    perm = np.random.permutation(n_samples)\n",
    "    train_end = int(train_percent * n_samples)\n",
    "    train = df.iloc[perm[:train_end]]\n",
    "    test = df.iloc[perm[train_end:]]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(filename):\n",
    "    df_samples = pd.read_csv(filename,sep=';',names=['V1','V2','V1V2','V2V1'])\n",
    "    df_samples['V1'] = convert_string_to_list(df_samples['V1'])\n",
    "    df_samples['V2'] = convert_string_to_list(df_samples['V2'])\n",
    "    # df_samples.head()\n",
    "    return df_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input(df_samples):\n",
    "    df_input = df_samples.filter(['V1','V2','V1V2']).rename(columns={'V1': 'A', 'V2': 'B', 'V1V2': 'AB'})\n",
    "    df_input = pd.concat([df_input,df_samples.filter(['V2','V1','V2V1']).rename(columns={'V2':'A', 'V1': 'B', 'V2V1': 'AB'})])\n",
    "    return df_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_format_and_split(filename):\n",
    "    df_samples = read_csv(filename)\n",
    "    df_input = format_input(df_samples)\n",
    "    return train_test_split(df_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(dim, optimizer):\n",
    "    model_filename = './results/model/seq_200relu_100relu_50ep__d'+str(dim)+'_opt-'+optimizer\n",
    "    json_file = open(model_filename+'.json')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    loaded_model.load_weights(model_filename+'.h5')\n",
    "    loaded_model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_json(model,config_name,dim,opt):\n",
    "    model_json = model.to_json()\n",
    "    model_name = 'results/model/'+config_name+'_d'+str(dim)+'_opt-'+opt+'.json'\n",
    "    with open(model_name,'w') as json_file:\n",
    "        json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_weights(model,config_name,dim,opt):\n",
    "    model_weights_name = 'results/model/'+config_name+'_d'+str(dim)+'_opt-'+opt+'.h5'\n",
    "    model.save_weights(model_weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data_to_plot(output_name,optimizer,dim,epoch,value):\n",
    "    with open(output_name,'a') as plot_file:\n",
    "        plot_file.write(optimizer+';'+str(dim)+';'+str(epoch)+';'+str(value)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(output_name,optimizer,dim,value):\n",
    "    with open(output_name,'a') as plot_file:\n",
    "        plot_file.write(optimizer+';'+str(dim)+';'+str(value)+'\\n')"
   ]
  }
 ]
}